{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are taking prediction results of a district, taken at different point of time (different months within a year). We are going to combine all prediction results to make a final prediction for that year.\n",
    "\n",
    "# import all required packages\n",
    "from PIL import Image\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "import pandas as pd\n",
    "import unittest\n",
    "import os, sys\n",
    "import shutil #for copying files\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change districts, and years accordingly\n",
    "''' \n",
    "districts = ['Bangalore','Chennai','Delhi','Gurgaon','Hyderabad','Kolkata','Mumbai']\n",
    "years=['2016','2017','2018','2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore\n",
      "Chennai\n",
      "Delhi\n",
      "Gurgaon\n",
      "Hyderabad\n",
      "Kolkata\n",
      "Mumbai\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Covert monthly predictions from .tif to .png\n",
    "'''\n",
    "for district in districts:\n",
    "    main_folder = 'Classification_'+district     #we have stored monthly predections in a folder named by district name\n",
    "    print(district)\n",
    "    os.makedirs(main_folder+\"/pngs\",exist_ok=True)\n",
    "    for infile in os.listdir(main_folder):\n",
    "        if infile[-4:] == \".tif\":                   #reading all tif files in given folder\n",
    "            im = Image.open(main_folder+\"/\"+infile)\n",
    "            im.save(main_folder+\"/pngs/\"+infile[:-4]+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining all required functions\n",
    "'''\n",
    "Rule-based post-classification correction\n",
    "\n",
    "merge the monthly predictions and overall median prediction to get a single prediction for year\n",
    "Pixel value 0 denotes Background, 1 denotes greenery, 2 denotes water, 3 benotes Built-Up, 4 denotes Barren land\n",
    "Input-\n",
    "1) monthly_pixel_predictions = list of predicted value of a particular pixel in the best 5 months of a particular year\n",
    "2) median_pixel_prediction = predicted value of the above pixel over the year median image\n",
    "'''  \n",
    "def merge_prediction(monthly_pixel_predictions, median_pixel_prediction):    \n",
    "    total_predictions = len(monthly_pixel_predictions)\n",
    "    \n",
    "    #find the count of each kind of pixel value for a pixel across all the given years\n",
    "    background_count = monthly_pixel_predictions.count(0)\n",
    "    green_count = monthly_pixel_predictions.count(1)\n",
    "    water_count = monthly_pixel_predictions.count(2)\n",
    "    builtup_count = monthly_pixel_predictions.count(3)\n",
    "    barrenland_count = monthly_pixel_predictions.count(4)\n",
    "    \n",
    "    #Applying different rules for post-classification error correction\n",
    "    \n",
    "    # Rule1: If pixel is predicted as background in all 5 months, consider it background for the entire year\n",
    "    if (background_count == total_predictions):\n",
    "        return '0'\n",
    "    \n",
    "    # Rule2: If pixel is predicted as water more times than green in 5 months, consider it water for the entire year\n",
    "    elif (water_count > 0 and green_count > 0 and water_count > 2 * green_count):\n",
    "        return '2'\n",
    "    \n",
    "    # Rule3: If pixel is predicted as water more than 50% times, consider it water for the entire year\n",
    "    elif (water_count >= 0.5 * total_predictions):\n",
    "        return '2'\n",
    "    \n",
    "    # Rule4: If pixel is predicted as green more times than water in 5 months, consider it green for the entire year\n",
    "    elif (water_count>0 and green_count>0 and water_count <= 2 * green_count ):\n",
    "        return '1'\n",
    "    \n",
    "    # Rule5: This rule helps to eliminate shadows which are mis-interpreted as water\n",
    "    elif (water_count != 0 and green_count == 0 ):\n",
    "        return str(median_pixel_prediction)\n",
    "    \n",
    "    # Rule6: After identifying water, if a pixel is predicted as green atleast once, consider it green for the entire year\n",
    "    elif ( green_count >=1 ):\n",
    "        return '1'\n",
    "    \n",
    "    # Rule7: If a pixel is neither green nor water, then it is barrenland or builtup as per majority for the entire year\n",
    "    elif((barrenland_count > builtup_count) and green_count==0 and water_count==0 ):\n",
    "        return '4'\n",
    "    \n",
    "    # Rule8: If a pixel is neither green nor water, then it is barrenland or builtup as per majority for the entire year\n",
    "    else:\n",
    "        return '3'\n",
    "    \n",
    "'''\n",
    "This function is used to find a future year whose image can be used to replicate a bad year with no good monthly images\n",
    "Input:\n",
    "a) bad_index- index of a year which needs replication\n",
    "b) years- list of available years under analysis\n",
    "c) replication_required_years- list of corrupt years for a district\n",
    "\n",
    "Output: target year whose image can be replicated to cover bad year. It is 0 when no such year is available   \n",
    "'''\n",
    "def find_non_corrupt_forward(bad_index, years, replication_required_years):\n",
    "    for k in range( bad_index+1, len(years) ):\n",
    "        if years[k] not in replication_required_years:\n",
    "            return years[k]\n",
    "    return 0 \n",
    "\n",
    "'''\n",
    "This function is used to find a past year whose image can be used to replicate a bad year with no good monthly images\n",
    "Input:\n",
    "a) bad_index- index of a year which needs replication\n",
    "b) years- list of available years under analysis\n",
    "c) replication_required_years- list of corrupt years for a district\n",
    "\n",
    "Output: target year whose image can be replicated to cover bad year. It is 0 when no such year is available\n",
    "'''\n",
    "def find_non_corrupt_backward(bad_index, years, replication_required_years):\n",
    "    for k in range( bad_index-1, -1, -1 ):\n",
    "        if years[k] not in replication_required_years:\n",
    "            return years[k]\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  6\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '01', '02', '12']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1483501, 2021457,   32335,  293622,  157531]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  6\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['11', '01', '02', '04']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1483501, 1947943,   28380,  320643,  207979]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  7\n",
      "Number of months available after filtering on BU pixels:  5\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '01', '04', '03', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1483501, 1977195,   37043,  299821,  190886]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  5\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['05', '02', '03', '04']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1483501, 1483742,   26164,  340091,  654948]))\n",
      "Years that require replication for distirct  Bangalore  are:  []\n",
      "Chennai\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  4\n",
      "Number of months available after filtering on BU pixels:  3\n",
      "The best months (max 5 and min 3) of this year are:  ['08', '10', '03']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([117523, 105069,   6070, 110585,   3485]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  2\n",
      "Number of months available after filtering on BU pixels:  2\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  6\n",
      "Number of months available after filtering on BU pixels:  6\n",
      "The best months (max 5 and min 3) of this year are:  ['09', '07', '05', '03', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([117523,  89938,   5079, 128470,   1722]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  8\n",
      "The best months (max 5 and min 3) of this year are:  ['12', '07', '02', '03', '04']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([117523, 103218,   4988, 114977,   2026]))\n",
      "Years that require replication for distirct  Chennai  are:  ['2017']\n",
      "Delhi\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  7\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '09', '06', '05']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1400094, 1130729,   25696,  692113,   64600]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  6\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['03', '10', '12', '11']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1400094, 1253935,   34109,  622047,    3047]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  10\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '09', '02', '03', '01']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1400094, 1359207,   24261,  520529,    9141]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  6\n",
      "The best months (max 5 and min 3) of this year are:  ['03', '02', '04', '05', '10']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1400094, 1272416,   21632,  580957,   38133]))\n",
      "Years that require replication for distirct  Delhi  are:  []\n",
      "Gurgaon\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  7\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['02', '12', '06', '05']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1141448, 1182408,   13052,  282170,  155727]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  6\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['03', '02', '12', '04']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1141448, 1080439,   59049,  461194,   32675]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  10\n",
      "Number of months available after filtering on BU pixels:  6\n",
      "The best months (max 5 and min 3) of this year are:  ['09', '01', '10', '11', '05']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1141448, 1426350,   13448,  152944,   40615]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  11\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['03', '08', '01', '10', '04']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([1141448, 1408836,    8936,  178899,   36686]))\n",
      "Years that require replication for distirct  Gurgaon  are:  []\n",
      "Hyderabad\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  8\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '09', '11', '12', '03']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([153791,  80469,   7570, 118319,   3291]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  10\n",
      "Number of months available after filtering on BU pixels:  9\n",
      "The best months (max 5 and min 3) of this year are:  ['11', '06', '09', '12', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([153791,  82233,   8329, 117328,   1759]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['09', '10', '04', '11', '05']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([153791,  82313,   8972, 115734,   2630]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  9\n",
      "The best months (max 5 and min 3) of this year are:  ['11', '08', '06', '03', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([153791,  71774,   8562, 127710,   1603]))\n",
      "Years that require replication for distirct  Hyderabad  are:  []\n",
      "Kolkata\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  4\n",
      "Number of months available after filtering on BU pixels:  3\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '11', '01']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([143324,  50048,   9090,  52286,    268]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  8\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['11', '06', '03', '12']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([143324,  48188,  12617,  50876,     11]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  8\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['04', '10', '05', '11', '03']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([143324,  40137,   6742,  64806,      7]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['04', '03', '05', '06', '11']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([143324,  44708,   6226,  60727,     31]))\n",
      "Years that require replication for distirct  Kolkata  are:  []\n",
      "Mumbai\n",
      "2016\n",
      "Number of months available after filtering on background pixels:  5\n",
      "Number of months available after filtering on BU pixels:  5\n",
      "The best months (max 5 and min 3) of this year are:  ['10', '11', '12', '03', '01']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([518379, 350472,  46948, 172726,   1125]))\n",
      "2017\n",
      "Number of months available after filtering on background pixels:  7\n",
      "Number of months available after filtering on BU pixels:  4\n",
      "The best months (max 5 and min 3) of this year are:  ['01', '03', '05', '04']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([518379, 346320,  63634, 151220,  10097]))\n",
      "2018\n",
      "Number of months available after filtering on background pixels:  8\n",
      "Number of months available after filtering on BU pixels:  7\n",
      "The best months (max 5 and min 3) of this year are:  ['11', '04', '03', '12', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([518379, 326121,  46598, 196722,   1830]))\n",
      "2019\n",
      "Number of months available after filtering on background pixels:  9\n",
      "Number of months available after filtering on BU pixels:  8\n",
      "The best months (max 5 and min 3) of this year are:  ['12', '04', '05', '10', '02']\n",
      "final_prediction  (array([0., 1., 2., 3., 4.]), array([518379, 349250,  33926, 186122,   1973]))\n",
      "Years that require replication for distirct  Mumbai  are:  []\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read all the different predictions of a district. \n",
    "Out of the 12 months for each year, we see which months have the maximum number of green pixels (Assuming them to be most accurate). \n",
    "The top 5 months are chosen to create the final pixel-level predictions for each year.\n",
    "'''\n",
    "for district in districts:\n",
    "    print(district)\n",
    "    main_folder = 'Classification_'+district     #we have downloaded monthly predections in a folder named by district name from google drive\n",
    "    os.makedirs(main_folder+\"/final\",exist_ok=True)\n",
    "    replication_required_years = [] #List of years for which this district cannot do month-wise correction due to bad satellite images\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        \n",
    "        #Find the minimum number of background pixels in the images of all months for this year\n",
    "        dataset = [ np.asarray(Image.open(main_folder+\"/pngs/\"+infile)) for infile in os.listdir(main_folder+\"/pngs/\") ]\n",
    "        backgroundPixels = [ np.unique(dataset[k],return_counts=True)[1][0] for k in range(len(dataset)) ]      \n",
    "        min_background_count = min(backgroundPixels) #All complete images of this district will have this number of background pixels only\n",
    "        \n",
    "        Green_pixs = []  #This list will store the key-value pairs where key=month and value=(#green pixels, #builtup pixels) predicted in that month   \n",
    "        \n",
    "        for infile in os.listdir(main_folder+\"/pngs/\"):\n",
    "            if 'Classification_'+district in infile and year in infile and 'median' not in infile: #reading all monthly predictions\n",
    "                im = np.asarray(Image.open(main_folder+\"/pngs/\"+infile))\n",
    "                if np.unique(im,return_counts=True)[1][0] > min_background_count:\n",
    "                    # Check that the if background pixels are increased by atmost 5%, include those months \n",
    "                    if ((np.unique(im,return_counts=True)[1][0] - min_background_count)/min_background_count) <= 0.05 :\n",
    "                        month = infile[-6:-4]\n",
    "                        Green_pixs.append((month, ( np.unique(im,return_counts=True)[1][1] , np.unique(im,return_counts=True)[1][3])))\n",
    "\n",
    "                else:\n",
    "                    month = infile[-6:-4]\n",
    "                    Green_pixs.append((month, ( np.unique(im,return_counts=True)[1][1] , np.unique(im,return_counts=True)[1][3])))\n",
    "                \n",
    "        Green_pixs.sort(key=lambda x:x[1],reverse=True) #sort the dictionary by values of #green pixels         \n",
    "        print(\"Number of months available after filtering on background pixels: \",len(Green_pixs))\n",
    "        \n",
    "        #Filter on the basis of tolerance against increase in builtup pixels i.e increase/decrease by atmost 40%\n",
    "        #The month with highest number of green pixels can be assumed to have the most accurate number of builtup pixels also\n",
    "        BU_threshold = Green_pixs[0][1][1]\n",
    "                \n",
    "        for entry in Green_pixs:\n",
    "            if abs(entry[1][1] - BU_threshold)/BU_threshold > 0.4:\n",
    "                Green_pixs.remove(entry)\n",
    "                \n",
    "        print(\"Number of months available after filtering on BU pixels: \",len(Green_pixs))\n",
    "        \n",
    "        best_months = [Green_pixs[i][0] for i in range(min(5,len(Green_pixs)))] #taking best 5 months on the basis of greenery\n",
    "        \n",
    "        \n",
    "        if not len(best_months) < 3:             \n",
    "            print(\"The best months (max 5 and min 3) of this year are: \",best_months)\n",
    "\n",
    "            best_month_paths = [main_folder+'/pngs/Classification_'+district+'_'+year+'_30mtr_'+best_month+'.png' for best_month in best_months]\n",
    "            best_predictions = [np.asarray(Image.open(best_month_path)) for best_month_path in best_month_paths]\n",
    "\n",
    "            year_median_path = main_folder+'/pngs/'+'Classification_'+district+'_'+year+'_30mtr_year_median.png'\n",
    "            year_median_prediction = np.asarray(Image.open(year_median_path))\n",
    "\n",
    "            image_dimension = best_predictions[0].shape\n",
    "            #print(image_dimension)\n",
    "\n",
    "            #Initializing the final prediction matrix for a particular year\n",
    "            final_prediction = np.zeros(image_dimension[0] * image_dimension[1]).reshape(image_dimension)\n",
    "            #print(final_prediction)\n",
    "\n",
    "            for i in range(image_dimension[0]):\n",
    "                for j in range(image_dimension[1]):\n",
    "                    x = [ best_predictions[k][i][j] for k in range(len(best_predictions)) ]\n",
    "                    final_prediction[i,j] = merge_prediction(x, year_median_prediction[i][j])\n",
    "\n",
    "            print(\"final_prediction \",np.unique(final_prediction,return_counts=True))\n",
    "\n",
    "            final_prediction = (Image.fromarray(final_prediction)).convert(\"L\")\n",
    "            final_prediction.save(main_folder+'/final/'+district+'_prediction_'+year+'.png')\n",
    "        \n",
    "        else: #If we did not get atleast 3 best months for this year\n",
    "            replication_required_years.append(year)\n",
    "    \n",
    "    print(\"Years that require replication for distirct \",district,\" are: \",replication_required_years)\n",
    "    for year in years:\n",
    "        if year in replication_required_years:\n",
    "            bad_index = years.index(year)\n",
    "            if(bad_index == 0 or bad_index == 1):\n",
    "                target_year = find_non_corrupt_forward(bad_index, years, replication_required_years)\n",
    "            elif(bad_index == len(years)-1 or bad_index == len(years)-2):\n",
    "                target_year = find_non_corrupt_backward(bad_index, years, replication_required_years)\n",
    "            else:\n",
    "                target_year = find_non_corrupt_forward(bad_index, years, replication_required_years)\n",
    "            \n",
    "            if(target_year == 0): #no replication found\n",
    "                print(\"Error! No way for replication. Discard district \",district,\" from analysis\")\n",
    "            else:\n",
    "                copy = Image.open(main_folder+'/final/'+district+'_prediction_'+target_year+'.png')\n",
    "                copy.save(main_folder+'/final/'+district+'_prediction_'+year+'.png')\n",
    "        \n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore\n",
      "Chennai\n",
      "Delhi\n",
      "Gurgaon\n",
      "Hyderabad\n",
      "Kolkata\n",
      "Mumbai\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Color coding the final prediction maps for a particular year. Uptill here the pixel values contain greyscale values. For easier visualization, we assign intuitive colors to different land-cover classes. These images will be stored at final/Color_coded_final_predictions subfolder for each district \n",
    "'''\n",
    "for district in districts:\n",
    "    print(district)\n",
    "    main_folder = 'Classification_'+district+\"/final\"     #we have downloaded monthly predections in a folder named by district name from google drive\n",
    "    os.makedirs(main_folder+\"/Color_coded_final_predictions\",exist_ok=True)\n",
    "    for year in years:\n",
    "        image_path = main_folder+'/'+district+'_prediction_'+year+'.png'  \n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert(\"RGBA\")\n",
    "        pixdata = img.load()\n",
    "        #print(img.getcolors()) #use this command to visualize already assigned colors to each label\n",
    "        \n",
    "        for y in range(img.size[1]):\n",
    "            for x in range(img.size[0]):\n",
    "                if pixdata[x, y] == (0, 0, 0, 255):      # background \n",
    "                    pixdata[x, y] = (0,0,0,0)            # black color\n",
    "                elif pixdata[x, y] == (1, 1, 1, 255):    # green\n",
    "                    pixdata[x, y] = (34,139,34, 255)     # green color\n",
    "                elif pixdata[x, y] == (2, 2, 2, 255):    # water\n",
    "                    pixdata[x, y] = (2, 4, 251, 255)     # blue color\n",
    "                elif pixdata[x, y] == (3, 3, 3, 255):    # built-up \n",
    "                    pixdata[x, y] = (255, 255, 102, 255) # yellow color\n",
    "                elif pixdata[x, y] == (4, 4, 4, 255):    # bareland\n",
    "                    pixdata[x, y] = (255, 80, 80, 255)   # red color\n",
    "\n",
    "        img.save(main_folder+\"/Color_coded_final_predictions/\"+district+'_colored_prediction_'+year+'.png')\n",
    "print(\"Done\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
